{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T02:41:29.293889Z",
     "start_time": "2025-05-08T02:41:29.289996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import logging\n",
    "from typing import List, Dict, Optional, Tuple"
   ],
   "id": "371d66ec703278d6",
   "outputs": [],
   "execution_count": 196
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T02:41:29.321579Z",
     "start_time": "2025-05-08T02:41:29.319697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')"
   ],
   "id": "de3c2049435c1008",
   "outputs": [],
   "execution_count": 197
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T02:41:29.523152Z",
     "start_time": "2025-05-08T02:41:29.340412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv(\"./input/train_dataset.csv\")\n",
    "test_df = pd.read_csv(\"./input/test_dataset.csv\")\n",
    "station_info_df = pd.read_csv(\"./input/station_info.csv\")\n",
    "sample_submission_df = pd.read_csv(\"./input/submission_sample.csv\")"
   ],
   "id": "3967744a4b0376c0",
   "outputs": [],
   "execution_count": 198
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T02:41:29.544372Z",
     "start_time": "2025-05-08T02:41:29.542377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_time_feature_bases(df: pd.DataFrame) -> List[str]:\n",
    "    time_cols = [col for col in df.columns if re.match(r\".+_\\d{1,2}$\", col)]\n",
    "    return sorted({col.rsplit(\"_\", 1)[0] for col in time_cols})"
   ],
   "id": "9981b398cd0ebb4f",
   "outputs": [],
   "execution_count": 199
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Resolving missing values",
   "id": "be5445549e1166de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T02:41:29.565802Z",
     "start_time": "2025-05-08T02:41:29.563879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_special_values_to_nan(df, special_values=[-9999, -999, -99, 9999]):\n",
    "    new_df = df.copy()\n",
    "    numeric_cols = new_df.select_dtypes(include=np.number).columns\n",
    "    for value in special_values:\n",
    "        count = (new_df[numeric_cols] == value).sum().sum()\n",
    "        if count > 0:\n",
    "            new_df[numeric_cols] = new_df[numeric_cols].replace(value, np.nan)\n",
    "    return new_df"
   ],
   "id": "5d08b124efd2ddfb",
   "outputs": [],
   "execution_count": 200
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T02:41:29.598236Z",
     "start_time": "2025-05-08T02:41:29.589316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def smart_median_imputation(df, feature_cols, group_cols=['station']):\n",
    "    result = df.copy()\n",
    "    valid_features = [col for col in feature_cols if col in result.columns and result[col].isna().any()]\n",
    "\n",
    "    for feature in valid_features:\n",
    "        for i in range(len(group_cols), 0, -1):\n",
    "            grp = group_cols[:i]\n",
    "            if all(g in result.columns for g in grp):\n",
    "                result[feature] = result.groupby(grp, observed=False)[feature].transform(lambda x: x.fillna(x.median()) if x.notna().any() else x)\n",
    "\n",
    "        if result[feature].isna().any():\n",
    "            global_median = result[feature].median()\n",
    "            fallback = 0 if pd.isna(global_median) else global_median\n",
    "            result[feature] = result[feature].fillna(fallback)\n",
    "            if pd.isna(global_median) and result[feature].isna().any():\n",
    "                print(f\"Warning: Could not impute column {feature} with median, filled with 0.\")\n",
    "\n",
    "    return result\n"
   ],
   "id": "c6fab0738d69c26a",
   "outputs": [],
   "execution_count": 201
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T02:41:29.623744Z",
     "start_time": "2025-05-08T02:41:29.620999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def domain_specific_imputation(df: pd.DataFrame, feature_prefix: str) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    is_changma = df['month'].isin([6, 7])\n",
    "\n",
    "    if feature_prefix == 'wind_direction':\n",
    "        cols = [f'{feature_prefix}_{h}' for h in range(24) if f'{feature_prefix}_{h}' in df.columns]\n",
    "        for col in cols:\n",
    "            mode_val = df.groupby('station')[col].transform(lambda x: x.mode().iloc[0] if not x.mode().empty else 0)\n",
    "            df[col] = df[col].fillna(mode_val).fillna(0)\n",
    "\n",
    "    elif feature_prefix == 'precipitation':\n",
    "        cols = [f'{feature_prefix}_{h}' for h in range(24) if f'{feature_prefix}_{h}' in df.columns]\n",
    "        for col in cols:\n",
    "            med = df[is_changma].groupby(['station', 'month'])[col].transform('median')\n",
    "            df.loc[is_changma, col] = df.loc[is_changma, col].fillna(med)\n",
    "            df.loc[~is_changma, col] = df.loc[~is_changma, col].fillna(0)\n",
    "\n",
    "    return df"
   ],
   "id": "97f655d4b3bad7cc",
   "outputs": [],
   "execution_count": 202
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T02:41:29.639719Z",
     "start_time": "2025-05-08T02:41:29.635556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def missing_values_pipeline(df: pd.DataFrame, n_neighbors=5, max_interpolation_gap=8) -> pd.DataFrame:\n",
    "    df_imputed = df.copy()\n",
    "\n",
    "    # Add month column, considering leap year\n",
    "    df_imputed['month'] = df_imputed['date'].str.split('-').str[0].astype(int)\n",
    "    df_imputed['day'] = df_imputed['date'].str.split('-').str[1].astype(int)\n",
    "    df_imputed['day_of_year'] = (df_imputed['month'] - 1) * 30 + df_imputed['day']\n",
    "\n",
    "    # 1. Convert special values\n",
    "    df_imputed = convert_special_values_to_nan(df_imputed)\n",
    "\n",
    "    numeric_cols = df_imputed.select_dtypes(include=np.number).columns.tolist()\n",
    "    cols_to_impute = [col for col in numeric_cols if col not in ['id', 'station', 'date', 'station_name', 'latitude', 'longitude', 'elevation']]\n",
    "\n",
    "    # 2. Interpolate small gaps within each 24-hour row\n",
    "    df_imputed[cols_to_impute] = df_imputed[cols_to_impute].interpolate(\n",
    "        method='linear',\n",
    "        axis=1,\n",
    "        limit=max_interpolation_gap,\n",
    "        limit_direction='both'\n",
    "    )\n",
    "    print(\"Step 2: Row-wise interpolation complete.\")\n",
    "\n",
    "    # 3. Domain-specific imputation\n",
    "    df_imputed = domain_specific_imputation(df_imputed, 'wind_direction')\n",
    "    df_imputed = domain_specific_imputation(df_imputed, 'precipitation')\n",
    "    print(\"Step 3: Domain-specific imputation complete.\")\n",
    "\n",
    "    # 4. KNN Imputation\n",
    "    cols_needing_knn = [col for col in cols_to_impute if df_imputed[col].isna().any()]\n",
    "\n",
    "    if cols_needing_knn:\n",
    "        print(f\"Step 4: Applying KNN Imputation to {len(cols_needing_knn)} columns...\")\n",
    "        # Scale data before KNN\n",
    "        scaler = StandardScaler()\n",
    "        # Fit scaler only on columns that will be imputed by KNN\n",
    "        scaled_values = scaler.fit_transform(df_imputed[cols_needing_knn])\n",
    "        df_scaled = pd.DataFrame(scaled_values, index=df_imputed.index, columns=cols_needing_knn)\n",
    "\n",
    "        # Apply KNNImputer\n",
    "        knn_imputer = KNNImputer(n_neighbors=n_neighbors, weights='distance')\n",
    "        imputed_scaled_values = knn_imputer.fit_transform(df_scaled)\n",
    "\n",
    "        imputed_values = scaler.inverse_transform(imputed_scaled_values)\n",
    "\n",
    "        df_imputed[cols_needing_knn] = imputed_values\n",
    "        print(\"Step 4: KNN Imputation complete.\")\n",
    "\n",
    "    else:\n",
    "        print(\"Step 4: No columns require KNN Imputation.\")\n",
    "\n",
    "    # 5. Final Fallback Imputation (Median)\n",
    "    cols_needing_fallback = [col for col in cols_to_impute if df_imputed[col].isna().any()]\n",
    "    if cols_needing_fallback:\n",
    "        print(f\"Step 5: Applying Fallback Median Imputation to {len(cols_needing_fallback)} columns...\")\n",
    "        df_imputed = smart_median_imputation(df_imputed, cols_needing_fallback, group_cols=['station'])\n",
    "        print(\"Step 5: Fallback Median Imputation complete.\")\n",
    "\n",
    "        remaining_nans = df_imputed[cols_to_impute].isna().sum().sum()\n",
    "        if remaining_nans > 0:\n",
    "            print(f\"Warning: {remaining_nans} NaNs still remain after fallback imputation. Filling with 0.\")\n",
    "            df_imputed[cols_to_impute] = df_imputed[cols_to_impute].fillna(0)\n",
    "    else:\n",
    "        print(\"Step 5: No columns require Fallback Imputation.\")\n",
    "\n",
    "\n",
    "    df_imputed = df_imputed.drop(columns=['day', 'month', 'day_of_year'])\n",
    "\n",
    "    return df_imputed\n"
   ],
   "id": "aef7898fa7264e5e",
   "outputs": [],
   "execution_count": 203
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T02:41:45.445821Z",
     "start_time": "2025-05-08T02:41:29.673320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_imputed = missing_values_pipeline(train_df)\n",
    "test_df_imputed = missing_values_pipeline(test_df)"
   ],
   "id": "9f0c69928ca2b503",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Row-wise interpolation complete.\n",
      "Step 3: Domain-specific imputation complete.\n",
      "Step 4: Applying KNN Imputation to 95 columns...\n",
      "Step 4: KNN Imputation complete.\n",
      "Step 5: No columns require Fallback Imputation.\n",
      "Step 2: Row-wise interpolation complete.\n",
      "Step 3: Domain-specific imputation complete.\n",
      "Step 4: Applying KNN Imputation to 133 columns...\n",
      "Step 4: KNN Imputation complete.\n",
      "Step 5: No columns require Fallback Imputation.\n"
     ]
    }
   ],
   "execution_count": 204
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T02:41:45.484766Z",
     "start_time": "2025-05-08T02:41:45.478132Z"
    }
   },
   "cell_type": "code",
   "source": "train_df_imputed.head()",
   "id": "89b5e61d841c53cc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   id  station station_name   date  cloud_cover_0  cloud_cover_1  \\\n",
       "0   0       98          동두천  01-01            0.0            0.0   \n",
       "1   1       98          동두천  01-02            0.0            0.0   \n",
       "2   2       98          동두천  01-03            0.0            0.0   \n",
       "3   3       98          동두천  01-04            0.0            0.0   \n",
       "4   4       98          동두천  01-05            0.0            0.0   \n",
       "\n",
       "   cloud_cover_10  cloud_cover_11  cloud_cover_12  cloud_cover_13  ...  \\\n",
       "0             9.0             0.0             3.0             3.0  ...   \n",
       "1             0.0             0.0             0.0             0.0  ...   \n",
       "2             0.0             0.0             0.0             0.0  ...   \n",
       "3             2.0             0.0             0.0             1.0  ...   \n",
       "4             0.0             0.0             0.0             0.0  ...   \n",
       "\n",
       "   wind_speed_23  wind_speed_3  wind_speed_4  wind_speed_5  wind_speed_6  \\\n",
       "0            2.3           0.6           0.3           0.7           0.6   \n",
       "1            0.7           0.2           0.0           1.1           1.3   \n",
       "2            0.4           1.5           0.8           0.8           0.9   \n",
       "3            0.9           0.3           0.5           0.2           0.5   \n",
       "4            1.4           1.1           1.6           1.4           1.8   \n",
       "\n",
       "   wind_speed_7  wind_speed_8  wind_speed_9  climatology_temp    target  \n",
       "0           0.7           0.8           0.1         -2.707143 -3.992857  \n",
       "1           0.5           0.9           0.4         -3.646429 -1.653571  \n",
       "2           1.0           1.1           0.1         -2.694643 -0.005357  \n",
       "3           1.3           0.5           0.2         -2.501786 -0.898214  \n",
       "4           0.5           1.1           0.6         -2.625000 -1.775000  \n",
       "\n",
       "[5 rows x 342 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>station</th>\n",
       "      <th>station_name</th>\n",
       "      <th>date</th>\n",
       "      <th>cloud_cover_0</th>\n",
       "      <th>cloud_cover_1</th>\n",
       "      <th>cloud_cover_10</th>\n",
       "      <th>cloud_cover_11</th>\n",
       "      <th>cloud_cover_12</th>\n",
       "      <th>cloud_cover_13</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_speed_23</th>\n",
       "      <th>wind_speed_3</th>\n",
       "      <th>wind_speed_4</th>\n",
       "      <th>wind_speed_5</th>\n",
       "      <th>wind_speed_6</th>\n",
       "      <th>wind_speed_7</th>\n",
       "      <th>wind_speed_8</th>\n",
       "      <th>wind_speed_9</th>\n",
       "      <th>climatology_temp</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>동두천</td>\n",
       "      <td>01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-2.707143</td>\n",
       "      <td>-3.992857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>동두천</td>\n",
       "      <td>01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-3.646429</td>\n",
       "      <td>-1.653571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>동두천</td>\n",
       "      <td>01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-2.694643</td>\n",
       "      <td>-0.005357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>98</td>\n",
       "      <td>동두천</td>\n",
       "      <td>01-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-2.501786</td>\n",
       "      <td>-0.898214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>98</td>\n",
       "      <td>동두천</td>\n",
       "      <td>01-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-2.625000</td>\n",
       "      <td>-1.775000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 342 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 205
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T02:41:45.554954Z",
     "start_time": "2025-05-08T02:41:45.547414Z"
    }
   },
   "cell_type": "code",
   "source": "train_df_imputed.isna().sum().sum() == test_df_imputed.isna().sum().sum() == 0",
   "id": "e8f98d6cccd62802",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 206
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T02:41:45.629971Z",
     "start_time": "2025-05-08T02:41:45.628244Z"
    }
   },
   "cell_type": "code",
   "source": "print(train_df_imputed.shape, test_df_imputed.shape)",
   "id": "897e15ac9d68ae2a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13132, 342) (3004, 341)\n"
     ]
    }
   ],
   "execution_count": 207
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T02:41:47.248733Z",
     "start_time": "2025-05-08T02:41:45.703296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_imputed.to_csv(\"./input/processed/train_df_imputed.csv\", index=False)\n",
    "test_df_imputed.to_csv(\"./input/processed/test_df_imputed.csv\", index=False)"
   ],
   "id": "14b721354f193a69",
   "outputs": [],
   "execution_count": 208
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
